import React, { useState, useEffect } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import CameraFeed from './Camerafeed';
import api from '../api';

const VoiceCommand = () => {
  const [showCamera, setShowCamera] = useState(false);
  const [detectedObject, setDetectedObject] = useState('');
  const [error, setError] = useState(null);

  const {
    transcript,
    listening,
    browserSupportsSpeechRecognition,
    resetTranscript,
  } = useSpeechRecognition();

  // âœ… Only one definition of handleVoiceDetected
  const handleVoiceDetected = async (object) => {
    console.log('âœ… Detected voice command for:', object);

    // ğŸ”” Log to backend
    try {
      await api.post('/', {
        object: object,  // Dynamically pass the object detected
        status: 'Missing',
      });
      console.log('âœ… Object status logged successfully.');
    } catch (err) {
      console.error('ğŸš« Error logging to backend:', err);
      setError('Failed to log object status');
    }

    // ğŸ“¢ Notify and open camera
    alert(`ğŸ“¢ ${object} is missing! Opening camera...`);
    setDetectedObject(object);
    setShowCamera(true);

    // ğŸ”„ Reset transcript
    resetTranscript();
  };

  useEffect(() => {
    console.log('ğŸ§ Starting speech recognition...');
    if (browserSupportsSpeechRecognition) {
      SpeechRecognition.startListening({ continuous: true });
    } else {
      alert('ğŸš« Your browser doesnâ€™t support speech recognition.');
    }
  }, [browserSupportsSpeechRecognition]);

  useEffect(() => {
    const lower = transcript.toLowerCase();
    console.log('ğŸ“ Transcript:', transcript);
    console.log('ğŸ” Lowercase:', lower);
    
    // Update for multiple object detection (Bottle and Key)
    if (
      lower.includes('bottle is missing') ||
      lower.includes('i lost the bottle') ||
      lower.includes('bottle lost')
    ) {
      handleVoiceDetected('Bottle');
    } else if (
      lower.includes('key is missing') ||
      lower.includes('i lost the key') ||
      lower.includes('key lost')
    ) {
      handleVoiceDetected('Key');
    }
  }, [transcript]);

  return (
    <div className="voice-command-container">
      <h3>ğŸ™ï¸ Voice Command</h3>
      <p className="voice-status">
        <strong>Status:</strong> {listening ? 'ğŸ§ Listening...' : 'âŒ Not listening'}
      </p>
      <p><strong>Transcript:</strong></p>
      <div className="transcript-box">{transcript || 'ğŸ¤ Waiting for voice input...'}</div>

      {error && <p className="error-message">{error}</p>}

      {showCamera && <CameraFeed detectedObject={detectedObject} />}
    </div>
  );
};

export default VoiceCommand;
